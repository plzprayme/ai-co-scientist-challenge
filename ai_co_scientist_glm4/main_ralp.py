#!/usr/bin/env python3
"""
RALP-MIRROR: RALP-optimized Meta-Learning Iterative Research System

ULTRAWORK RALPì— ì˜í•´ ë¬´í•œìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ë©”ì¸ ë£¨í”„
glm 4.7 ëª¨ë¸ë§Œ ì‚¬ìš©

Usage (by RALP):
    while True:
        python main_ralp.py
"""

import json
import os
import sys
from datetime import datetime
from pathlib import Path

# ì„¤ì •
WORKSPACE = Path("workspace")
STATE_FILE = WORKSPACE / "state.json"
RUBRIC_FILE = WORKSPACE / "rubric.json"
SUBMISSION_DIR = WORKSPACE / "submission"
HISTORY_DIR = WORKSPACE / "history"
LEARNINGS_DIR = WORKSPACE / "learnings"

# ì‹¬ì‚¬ ê¸°ì¤€ (100ì  ë§Œì )
RUBRIC = {
    "practicality": {"max": 20, "name": "ì£¼ì œì˜ ì‹¤ìš©ì„±", "description": "ì—°êµ¬ê°€ ì‹¤ì œë¡œ ìœ ì˜ë¯¸í•˜ê³  ì‹¤ì§ˆì ì¸ ë¬¸ì œë¥¼ ë‹¤ë£¨ëŠ”ê°€"},
    "methodology": {"max": 20, "name": "ë°©ë²•ë¡ ì˜ ì ì ˆì„±", "description": "ì—°êµ¬ ë°©ë²•ë¡ ì´ ëª…í™•í•˜ê³  ê³¼í•™ì ì¸ê°€"},
    "data_quality": {"max": 25, "name": "ë°ì´í„°ì˜ ì ì ˆì„±", "description": "ë°ì´í„°ê°€ ë…¼ë¦¬ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ê°€"},
    "conclusion": {"max": 10, "name": "ê²°ë¡ ì˜ í•©ë¦¬ì„±", "description": "ê²°ë¡ ì´ ê³¼í•™ì  ì‚¬ì‹¤ì— ë¶€í•©í•˜ëŠ”ê°€"},
    "readability": {"max": 5, "name": "ì „ë‹¬ë ¥ ë° ê°€ë…ì„±", "description": "ì˜ë¬¸ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì „ë‹¬ë˜ì—ˆëŠ”ê°€"},
    "creativity": {"max": 20, "name": "ì—°êµ¬ì˜ ì°½ì˜ì„±", "description": "ì°¨ë³„í™”ëœ ì°½ì˜ì  ì ‘ê·¼ì¸ê°€"},
    "ai_contribution": {"type": "pass_fail", "name": "AI ì—°êµ¬ê¸°ì—¬ë„", "description": "AIê°€ ì¶©ë¶„íˆ ê¸°ì—¬í–ˆëŠ”ê°€"}
}

TARGET_SCORE = 85
MAX_ITERATIONS = 50


def init_workspace():
    """ì‘ì—… ê³µê°„ ì´ˆê¸°í™”"""
    WORKSPACE.mkdir(exist_ok=True)
    SUBMISSION_DIR.mkdir(exist_ok=True)
    HISTORY_DIR.mkdir(exist_ok=True)
    LEARNINGS_DIR.mkdir(exist_ok=True)
    
    # ì‹¬ì‚¬ ê¸°ì¤€ ì €ì¥
    with open(RUBRIC_FILE, 'w', encoding='utf-8') as f:
        json.dump(RUBRIC, f, ensure_ascii=False, indent=2)
    
    # ì´ˆê¸° ìƒíƒœ
    if not STATE_FILE.exists():
        save_state({
            "iteration": 0,
            "phase": "init",
            "best_score": 0,
            "current_score": 0,
            "target_score": TARGET_SCORE,
            "improvements_history": [],
            "weaknesses_history": [],
            "paper_version": "1.0.0",
            "timestamp": datetime.now().isoformat()
        })


def save_state(state):
    """ìƒíƒœ ì €ì¥ (íŒŒì¼ ê¸°ë°˜)"""
    state['timestamp'] = datetime.now().isoformat()
    with open(STATE_FILE, 'w', encoding='utf-8') as f:
        json.dump(state, f, ensure_ascii=False, indent=2)


def load_state():
    """ìƒíƒœ ë¡œë“œ"""
    with open(STATE_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)


def glm4_generate(prompt, temperature=0.7, max_tokens=4000):
    """
    glm 4.7 API í˜¸ì¶œ (ì‹¤ì œ êµ¬í˜„ ì‹œ API í‚¤ í•„ìš”)
    
    Args:
        prompt: ì…ë ¥ í”„ë¡¬í”„íŠ¸
        temperature: ì°½ì˜ì„± (0.0~1.0)
        max_tokens: ìµœëŒ€ í† í° ìˆ˜
    
    Returns:
        ìƒì„±ëœ í…ìŠ¤íŠ¸
    """
    # TODO: ì‹¤ì œ glm 4.7 API ì—°ë™
    # from zhipuai import ZhipuAI
    # client = ZhipuAI(api_key="YOUR_API_KEY")
    # response = client.chat.completions.create(
    #     model="glm-4.7",
    #     messages=[{"role": "user", "content": prompt}],
    #     temperature=temperature,
    #     max_tokens=max_tokens
    # )
    # return response.choices[0].message.content
    
    # í˜„ì¬ëŠ” mock êµ¬í˜„ (ì‹¤ì œ API ì—°ë™ í•„ìš”)
    return f"[GLM-4.7 OUTPUT for: {prompt[:50]}...]"


def glm4_generate_json(prompt, temperature=0.7):
    """JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µë°›ê¸°"""
    response = glm4_generate(prompt, temperature)
    # JSON íŒŒì‹±
    try:
        # ì½”ë“œ ë¸”ë¡ ì œê±°
        if "```json" in response:
            response = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            response = response.split("```")[1].split("```")[0]
        return json.loads(response.strip())
    except:
        return {"error": "JSON parsing failed", "raw": response}


def search_arxiv(query, max_results=10):
    """arxiv ë…¼ë¬¸ ê²€ìƒ‰"""
    try:
        import arxiv
        search = arxiv.Search(
            query=query,
            max_results=max_results,
            sort_by=arxiv.SortCriterion.Relevance
        )
        papers = []
        for result in search.results():
            papers.append({
                "title": result.title,
                "authors": [str(a) for a in result.authors],
                "summary": result.summary,
                "year": result.published.year,
                "url": result.pdf_url,
                "entry_id": result.entry_id
            })
        return papers
    except Exception as e:
        print(f"arxiv ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []


def phase_init(state):
    """ì´ˆê¸°í™” Phase"""
    print("\n" + "="*60)
    print("[PHASE: INIT] RALP-MIRROR ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
    print("="*60)
    
    # ì—°êµ¬ ì£¼ì œ ì„¤ì •
    research_topic = state.get('research_topic', 'AI-driven methodology for enhancing scientific research efficiency')
    
    print(f"ì—°êµ¬ ì£¼ì œ: {research_topic}")
    print(f"ëª©í‘œ ì ìˆ˜: {TARGET_SCORE}")
    print(f"ìµœëŒ€ ë°˜ë³µ: {MAX_ITERATIONS}")
    
    state['research_topic'] = research_topic
    state['phase'] = 'research'
    
    save_state(state)
    print("\nâ†’ ë‹¤ìŒ Phase: research")


def phase_research(state):
    """ì—°êµ¬ ìˆ˜í–‰ Phase"""
    print("\n" + "="*60)
    print(f"[PHASE: RESEARCH] Iteration {state['iteration'] + 1}")
    print("="*60)
    
    iteration = state['iteration'] + 1
    topic = state['research_topic']
    
    # 1. ë¬¸í—Œ ê²€ìƒ‰
    print("\n[1/4] ë¬¸í—Œ ê²€ìƒ‰ ì¤‘...")
    papers = search_arxiv(topic, max_results=10)
    print(f"  - {len(papers)}ê°œ ë…¼ë¬¸ ë°œê²¬")
    
    # 2. ë…¼ë¬¸ ì‘ì„±
    print("\n[2/4] ì—°êµ¬ë³´ê³ ì„œ ì‘ì„± ì¤‘...")
    paper_prompt = f"""
    ì—°êµ¬ ì£¼ì œ: {topic}
    
    ê´€ë ¨ ë…¼ë¬¸:
    {json.dumps([p['title'] for p in papers[:5]], ensure_ascii=False, indent=2)}
    
    ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•™ìˆ  ë…¼ë¬¸ í˜•íƒœì˜ ì—°êµ¬ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    
    ë‹¤ìŒ ì„¹ì…˜ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
    1. Title
    2. Abstract (250-300 words)
    3. Keywords (3-5ê°œ)
    4. Introduction
    5. Related Work
    6. Methodology
    7. Results
    8. Discussion
    9. Conclusion
    10. References
    
    ì˜ë¬¸ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    """
    
    paper = glm4_generate(paper_prompt, temperature=0.7)
    
    # íŒŒì¼ë¡œ ì €ì¥
    paper_file = SUBMISSION_DIR / "paper.md"
    with open(paper_file, 'w', encoding='utf-8') as f:
        f.write(paper)
    print(f"  - ì €ì¥ë¨: {paper_file}")
    
    # 3. AI í™œìš©ë³´ê³ ì„œ ì‘ì„±
    print("\n[3/4] AI í™œìš©ë³´ê³ ì„œ ì‘ì„± ì¤‘...")
    ai_usage_prompt = f"""
    ì´ ì—°êµ¬ì—ì„œ AI(glm 4.7)ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ í™œìš©í–ˆë‹¤ëŠ” ë‚´ìš©ì˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”:
    
    - ë¬¸í—Œ ê²€ìƒ‰ ë° ë¶„ì„
    - ì—°êµ¬ë³´ê³ ì„œ ì‘ì„±
    - ë°ì´í„° ë¶„ì„
    - ê²°ê³¼ í•´ì„
    
    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±:
    1. AI í™œìš© ì²´í¬ë¦¬ìŠ¤íŠ¸
    2. AI ìƒí˜¸ì‘ìš© ë¡œê·¸
    3. AI ê¸°ì—¬ë„ ìì²´ í‰ê°€ (50% ì´ìƒ)
    4. í™œìš© URL ëª©ë¡
    """
    
    ai_usage = glm4_generate(ai_usage_prompt, temperature=0.5)
    
    ai_usage_file = SUBMISSION_DIR / "ai_usage.md"
    with open(ai_usage_file, 'w', encoding='utf-8') as f:
        f.write(ai_usage)
    print(f"  - ì €ì¥ë¨: {ai_usage_file}")
    
    # 4. ë°ì´í„° ëª©ë¡ ì‘ì„±
    print("\n[4/4] ë°ì´í„° ëª©ë¡ ì‘ì„± ì¤‘...")
    data_list = f"""# í™œìš© ë°ì´í„° ëª©ë¡

## ê³µê°œ ë°ì´í„°
- arXiv ë…¼ë¬¸ ë°ì´í„° (ê²€ìƒ‰ì–´: {topic})

## ë°ì´í„° ì²˜ë¦¬ ë°©ë²•
- ìë™ í¬ë¡¤ë§
- ìš”ì•½ ì¶”ì¶œ
- í‚¤ì›Œë“œ ë¶„ì„
"""
    
    data_list_file = SUBMISSION_DIR / "data_list.md"
    with open(data_list_file, 'w', encoding='utf-8') as f:
        f.write(data_list)
    print(f"  - ì €ì¥ë¨: {data_list_file}")
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state['iteration'] = iteration
    state['phase'] = 'evaluate'
    
    save_state(state)
    print("\nâ†’ ë‹¤ìŒ Phase: evaluate")


def phase_evaluate(state):
    """í‰ê°€ Phase - glm 4.7ë¡œ 3ë²ˆ í‰ê°€ (self-consistency)"""
    print("\n" + "="*60)
    print(f"[PHASE: EVALUATE] Iteration {state['iteration']}")
    print("="*60)
    
    # ì œì¶œë¬¼ ë¡œë“œ
    paper_file = SUBMISSION_DIR / "paper.md"
    with open(paper_file, 'r', encoding='utf-8') as f:
        paper = f.read()
    
    print("\n[Self-Consistency Evaluation]")
    print("glm 4.7ë¡œ 3ë²ˆ í‰ê°€ (temperature: 0.3, 0.7, 1.0)")
    
    evaluations = []
    temps = [0.3, 0.7, 1.0]
    
    for i, temp in enumerate(temps, 1):
        print(f"\n  í‰ê°€ {i}/3 (temp={temp})...")
        
        eval_prompt = f"""
        ë‹¹ì‹ ì€ 2026 AI Co-Scientist Challenge Koreaì˜ ì‹¬ì‚¬ìœ„ì›ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ì—°êµ¬ë³´ê³ ì„œë¥¼ ì‹¬ì‚¬ ê¸°ì¤€ì— ë”°ë¼ í‰ê°€í•˜ì„¸ìš”.
        
        === ì—°êµ¬ë³´ê³ ì„œ ===
        {paper[:3000]}...
        
        === ì‹¬ì‚¬ ê¸°ì¤€ ===
        1. ì£¼ì œì˜ ì‹¤ìš©ì„± (20ì ): ì—°êµ¬ê°€ ì‹¤ì œë¡œ ìœ ì˜ë¯¸í•œê°€
        2. ë°©ë²•ë¡ ì˜ ì ì ˆì„± (20ì ): ë°©ë²•ë¡ ì´ ëª…í™•í•˜ê³  ê³¼í•™ì ì¸ê°€
        3. ë°ì´í„°ì˜ ì ì ˆì„± (25ì ): ë°ì´í„°ê°€ ë…¼ë¦¬ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ê°€
        4. ê²°ë¡ ì˜ í•©ë¦¬ì„± (10ì ): ê²°ë¡ ì´ ê³¼í•™ì  ì‚¬ì‹¤ì— ë¶€í•©í•˜ëŠ”ê°€
        5. ì „ë‹¬ë ¥ ë° ê°€ë…ì„± (5ì ): ì˜ë¬¸ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì „ë‹¬ë˜ì—ˆëŠ”ê°€
        6. ì—°êµ¬ì˜ ì°½ì˜ì„± (20ì ): ì°¨ë³„í™”ëœ ì°½ì˜ì  ì ‘ê·¼ì¸ê°€
        7. AI ì—°êµ¬ê¸°ì—¬ë„ (Pass/Fail): AIê°€ ì¶©ë¶„íˆ ê¸°ì—¬í–ˆëŠ”ê°€
        
        ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
        {{
            "practicality": {{"score": 0-20, "reason": "...", "improvement": "..."}},
            "methodology": {{"score": 0-20, "reason": "...", "improvement": "..."}},
            "data_quality": {{"score": 0-25, "reason": "...", "improvement": "..."}},
            "conclusion": {{"score": 0-10, "reason": "...", "improvement": "..."}},
            "readability": {{"score": 0-5, "reason": "...", "improvement": "..."}},
            "creativity": {{"score": 0-20, "reason": "...", "improvement": "..."}},
            "ai_contribution": {{"pass": true/false, "reason": "..."}},
            "total_score": 0-100,
            "top_weaknesses": ["...", "..."],
            "top_improvements": ["...", "..."]
        }}
        """
        
        result = glm4_generate_json(eval_prompt, temperature=temp)
        evaluations.append(result)
    
    # ì¤‘ì•™ê°’ ì§‘ê³„
    print("\n[ì§‘ê³„ ê²°ê³¼]")
    
    def median(values):
        sorted_vals = sorted(values)
        n = len(sorted_vals)
        if n % 2 == 0:
            return (sorted_vals[n//2-1] + sorted_vals[n//2]) / 2
        return sorted_vals[n//2]
    
    aggregated = {
        "practicality": {
            "score": median([e.get('practicality', {}).get('score', 0) for e in evaluations]),
            "reason": evaluations[1].get('practicality', {}).get('reason', '')  # ì¤‘ê°„ê°’ ì‚¬ìš©
        },
        "methodology": {
            "score": median([e.get('methodology', {}).get('score', 0) for e in evaluations]),
            "reason": evaluations[1].get('methodology', {}).get('reason', '')
        },
        "data_quality": {
            "score": median([e.get('data_quality', {}).get('score', 0) for e in evaluations]),
            "reason": evaluations[1].get('data_quality', {}).get('reason', '')
        },
        "conclusion": {
            "score": median([e.get('conclusion', {}).get('score', 0) for e in evaluations]),
            "reason": evaluations[1].get('conclusion', {}).get('reason', '')
        },
        "readability": {
            "score": median([e.get('readability', {}).get('score', 0) for e in evaluations]),
            "reason": evaluations[1].get('readability', {}).get('reason', '')
        },
        "creativity": {
            "score": median([e.get('creativity', {}).get('score', 0) for e in evaluations]),
            "reason": evaluations[1].get('creativity', {}).get('reason', '')
        },
        "ai_contribution": {
            "pass": all(e.get('ai_contribution', {}).get('pass', False) for e in evaluations),
            "reason": evaluations[1].get('ai_contribution', {}).get('reason', '')
        }
    }
    
    total = sum([
        aggregated['practicality']['score'],
        aggregated['methodology']['score'],
        aggregated['data_quality']['score'],
        aggregated['conclusion']['score'],
        aggregated['readability']['score'],
        aggregated['creativity']['score']
    ])
    
    aggregated['total_score'] = total
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\n  ì´ì : {total}/100")
    print(f"  AI ê¸°ì—¬ë„: {'PASS' if aggregated['ai_contribution']['pass'] else 'FAIL'}")
    print("\n  ì„¸ë¶€ ì ìˆ˜:")
    for criterion, data in aggregated.items():
        if criterion not in ['total_score', 'ai_contribution']:
            max_score = RUBRIC[criterion]['max']
            print(f"    - {criterion}: {data['score']:.1f}/{max_score}")
    
    # íˆìŠ¤í† ë¦¬ ì €ì¥
    history_file = HISTORY_DIR / f"iter_{state['iteration']:03d}.json"
    with open(history_file, 'w', encoding='utf-8') as f:
        json.dump({
            'iteration': state['iteration'],
            'evaluations': evaluations,
            'aggregated': aggregated,
            'timestamp': datetime.now().isoformat()
        }, f, ensure_ascii=False, indent=2)
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state['current_score'] = total
    state['last_evaluation'] = aggregated
    
    # ì•½ì  ìˆ˜ì§‘
    weaknesses = []
    for criterion, data in aggregated.items():
        if criterion in RUBRIC and RUBRIC[criterion].get('max'):
            max_score = RUBRIC[criterion]['max']
            if data['score'] < max_score * 0.8:
                weaknesses.append({
                    'criterion': criterion,
                    'score': data['score'],
                    'max': max_score,
                    'gap': max_score - data['score'],
                    'reason': data.get('reason', ''),
                    'improvement': data.get('improvement', '')
                })
    
    state['current_weaknesses'] = sorted(weaknesses, key=lambda x: x['gap'], reverse=True)
    
    # ëª©í‘œ ë‹¬ì„± í™•ì¸
    if total >= TARGET_SCORE and aggregated['ai_contribution']['pass']:
        print(f"\nğŸ‰ ëª©í‘œ ë‹¬ì„±! ({total} >= {TARGET_SCORE})")
        state['phase'] = 'finalize'
    else:
        print(f"\nâ†’ ëª©í‘œ ë¯¸ë‹¬ ({total} < {TARGET_SCORE})")
        state['phase'] = 'improve'
    
    # ìµœê³  ì ìˆ˜ ì—…ë°ì´íŠ¸
    if total > state['best_score']:
        state['best_score'] = total
        print(f"âœ¨ ìƒˆë¡œìš´ ìµœê³  ì ìˆ˜: {total}")
    
    save_state(state)


def phase_improve(state):
    """ê°œì„  Phase"""
    print("\n" + "="*60)
    print(f"[PHASE: IMPROVE] Iteration {state['iteration']}")
    print("="*60)
    
    weaknesses = state.get('current_weaknesses', [])
    
    if not weaknesses:
        print("ê°œì„ í•  ì•½ì ì´ ì—†ìŠµë‹ˆë‹¤.")
        state['phase'] = 'research'
        save_state(state)
        return
    
    print(f"\n[ê°œì„  ëŒ€ìƒ] {len(weaknesses)}ê°œ ì•½ì ")
    for i, w in enumerate(weaknesses[:3], 1):
        print(f"  {i}. {w['criterion']}: {w['score']:.1f}/{w['max']} (gap: {w['gap']:.1f})")
        print(f"     â†’ {w.get('improvement', 'ê°œì„  í•„ìš”')}")
    
    # ë…¼ë¬¸ ë¡œë“œ
    paper_file = SUBMISSION_DIR / "paper.md"
    with open(paper_file, 'r', encoding='utf-8') as f:
        paper = f.read()
    
    # ê°œì„ 
    print("\n[ê°œì„  ì¤‘...]")
    
    improve_prompt = f"""
    ë‹¤ìŒ ì—°êµ¬ë³´ê³ ì„œë¥¼ ê°œì„ í•˜ì„¸ìš”.
    
    === í˜„ì¬ ë…¼ë¬¸ ===
    {paper}
    
    === ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ ===
    {json.dumps(weaknesses[:3], ensure_ascii=False, indent=2)}
    
    ìœ„ ì•½ì ë“¤ì„ í•´ê²°í•˜ì—¬ ê°œì„ ëœ ë…¼ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”.
    ì „ì²´ êµ¬ì¡°ëŠ” ìœ ì§€í•˜ë©´ì„œ í•´ë‹¹ ë¶€ë¶„ë§Œ ê°œì„ í•˜ì„¸ìš”.
    """
    
    improved_paper = glm4_generate(improve_prompt, temperature=0.8)
    
    # ì €ì¥
    with open(paper_file, 'w', encoding='utf-8') as f:
        f.write(improved_paper)
    
    print("  âœ“ ë…¼ë¬¸ ê°œì„  ì™„ë£Œ")
    
    # í•™ìŠµ ë‚´ìš© ì €ì¥
    learnings_file = LEARNINGS_DIR / "improvements.json"
    learnings = []
    if learnings_file.exists():
        with open(learnings_file, 'r', encoding='utf-8') as f:
            learnings = json.load(f)
    
    learnings.append({
        'iteration': state['iteration'],
        'weaknesses': weaknesses[:3],
        'timestamp': datetime.now().isoformat()
    })
    
    with open(learnings_file, 'w', encoding='utf-8') as f:
        json.dump(learnings, f, ensure_ascii=False, indent=2)
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state['phase'] = 'evaluate'
    state['improvements_history'].append({
        'iteration': state['iteration'],
        'weaknesses': [w['criterion'] for w in weaknesses[:3]]
    })
    
    save_state(state)
    print("\nâ†’ ë‹¤ìŒ Phase: evaluate")


def phase_finalize(state):
    """ìµœì¢… ì œì¶œ Phase"""
    print("\n" + "="*60)
    print("[PHASE: FINALIZE] ìµœì¢… ì œì¶œë¬¼ ì¤€ë¹„")
    print("="*60)
    
    # ì œì¶œë¬¼ ì••ì¶•
    import zipfile
    
    submission_zip = WORKSPACE / "submission.zip"
    
    with zipfile.ZipFile(submission_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for file in SUBMISSION_DIR.iterdir():
            if file.is_file():
                zipf.write(file, file.name)
                print(f"  ì¶”ê°€: {file.name}")
    
    print(f"\nâœ… ì œì¶œë¬¼ ìƒì„± ì™„ë£Œ: {submission_zip}")
    
    # ìµœì¢… ë³´ê³ ì„œ
    report = f"""
# RALP-MIRROR ìµœì¢… ë³´ê³ ì„œ

## ì‹¤í–‰ ìš”ì•½
- ì´ ë°˜ë³µ íšŸìˆ˜: {state['iteration']}
- ìµœê³  ì ìˆ˜: {state['best_score']}
- ìµœì¢… ì ìˆ˜: {state['current_score']}
- ëª©í‘œ ì ìˆ˜: {TARGET_SCORE}

## ê°œì„  ì´ë ¥
{json.dumps(state['improvements_history'], ensure_ascii=False, indent=2)}

## ì œì¶œë¬¼ ëª©ë¡
- paper.md: ì—°êµ¬ë³´ê³ ì„œ
- ai_usage.md: AI í™œìš©ë³´ê³ ì„œ
- data_list.md: ë°ì´í„° ëª©ë¡

## ìƒì„± ì‹œê°„
{datetime.now().isoformat()}
"""
    
    report_file = WORKSPACE / "FINAL_REPORT.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nğŸ“„ ìµœì¢… ë³´ê³ ì„œ: {report_file}")
    print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state['phase'] = 'completed'
    save_state(state)


def main():
    """RALPì— ì˜í•´ ë¬´í•œìœ¼ë¡œ í˜¸ì¶œë˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    
    # ì‘ì—… ê³µê°„ ì´ˆê¸°í™”
    init_workspace()
    
    # ìƒíƒœ ë¡œë“œ
    state = load_state()
    
    print(f"\n[RALP-MIRROR] Current Phase: {state['phase']}")
    print(f"Iteration: {state['iteration']}")
    print(f"Best Score: {state['best_score']}")
    
    # Phaseë³„ ì‹¤í–‰
    if state['phase'] == 'init':
        phase_init(state)
    
    elif state['phase'] == 'research':
        phase_research(state)
    
    elif state['phase'] == 'evaluate':
        phase_evaluate(state)
    
    elif state['phase'] == 'improve':
        phase_improve(state)
    
    elif state['phase'] == 'finalize':
        phase_finalize(state)
    
    elif state['phase'] == 'completed':
        print("\nâœ… ì´ë¯¸ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return 0
    
    return 1  # ê³„ì† ì‹¤í–‰ í•„ìš”


if __name__ == "__main__":
    sys.exit(main())
